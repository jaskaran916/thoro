{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d2ba167",
   "metadata": {
    "papermill": {
     "duration": 0.008046,
     "end_time": "2024-04-17T18:30:26.019957",
     "exception": false,
     "start_time": "2024-04-17T18:30:26.011911",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Importing libraries and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca06e5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T18:30:26.033008Z",
     "iopub.status.busy": "2024-04-17T18:30:26.032446Z",
     "iopub.status.idle": "2024-04-17T18:30:53.133255Z",
     "shell.execute_reply": "2024-04-17T18:30:53.131846Z"
    },
    "papermill": {
     "duration": 27.11068,
     "end_time": "2024-04-17T18:30:53.136087",
     "exception": false,
     "start_time": "2024-04-17T18:30:26.025407",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sudo] password for jaskaran: "
     ]
    }
   ],
   "source": [
    "!sudo apt install python3-p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "670f0feb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T18:30:53.149199Z",
     "iopub.status.busy": "2024-04-17T18:30:53.148845Z",
     "iopub.status.idle": "2024-04-17T18:31:01.492498Z",
     "shell.execute_reply": "2024-04-17T18:31:01.491138Z"
    },
    "papermill": {
     "duration": 8.353292,
     "end_time": "2024-04-17T18:31:01.495093",
     "exception": false,
     "start_time": "2024-04-17T18:30:53.141801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Import necessary libraries\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m  \u001b[38;5;66;03m# Import NumPy for handling numerical operations\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m  \u001b[38;5;66;03m# Import Pandas for data manipulation and analysis\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m  \u001b[38;5;66;03m# Import Warnings to suppress unnecessary warnings\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Suppress warning messages\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np  # Import NumPy for handling numerical operations\n",
    "import pandas as pd  # Import Pandas for data manipulation and analysis\n",
    "import warnings  # Import Warnings to suppress unnecessary warnings\n",
    "\n",
    "# Suppress warning messages\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Import SHAP for interpreting model predictions\n",
    "import shap\n",
    "\n",
    "# Import matplotlib for data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import CatBoostRegressor for building a regression model\n",
    "from catboost import Pool, CatBoostRegressor\n",
    "\n",
    "# Import mean_squared_error for evaluating model performance\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Import train_test_split for splitting the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import RareLabelEncoder from feature_engine.encoding for encoding categorical features\n",
    "from feature_engine.encoding import RareLabelEncoder\n",
    "\n",
    "# Import CountVectorizer from sklearn.feature_extraction.text for text feature extraction\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Import ast and re for working with text and regular expressions\n",
    "import ast\n",
    "import re\n",
    "\n",
    "# Set Pandas options to display a maximum of 1000 rows\n",
    "pd.set_option('display.max_rows', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac617c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4ef949",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T18:31:01.507633Z",
     "iopub.status.busy": "2024-04-17T18:31:01.507123Z",
     "iopub.status.idle": "2024-04-17T18:31:04.346007Z",
     "shell.execute_reply": "2024-04-17T18:31:04.344304Z"
    },
    "papermill": {
     "duration": 2.848511,
     "end_time": "2024-04-17T18:31:04.349138",
     "exception": false,
     "start_time": "2024-04-17T18:31:01.500627",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df = pd.read_csv('/kaggle/input/huggingface-co-model-catalogue/Models.csv') # Reads the dataset from a CSV file into a Pandas DataFrame\n",
    "item0 = df.shape[0]  # Stores the initial number of rows in the DataFrame\n",
    "df = df.drop_duplicates()  # Removes duplicate rows from the DataFrame\n",
    "item1 = df.shape[0]  # Stores the number of rows after removing duplicates\n",
    "print(f\"There are {item0-item1} duplicates found in the dataset\")  # Prints the number of duplicates that were removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22326f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T18:31:04.362697Z",
     "iopub.status.busy": "2024-04-17T18:31:04.362342Z",
     "iopub.status.idle": "2024-04-17T18:31:04.420773Z",
     "shell.execute_reply": "2024-04-17T18:31:04.419691Z"
    },
    "papermill": {
     "duration": 0.067332,
     "end_time": "2024-04-17T18:31:04.423016",
     "exception": false,
     "start_time": "2024-04-17T18:31:04.355684",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check for my own results there \n",
    "author_name = \"dima806\"\n",
    "author_df = df[df['author']==author_name]\n",
    "print(author_df.shape)\n",
    "author_df.sample(5).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a6e512",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T18:31:04.436198Z",
     "iopub.status.busy": "2024-04-17T18:31:04.435854Z",
     "iopub.status.idle": "2024-04-17T18:31:04.457057Z",
     "shell.execute_reply": "2024-04-17T18:31:04.456231Z"
    },
    "papermill": {
     "duration": 0.030634,
     "end_time": "2024-04-17T18:31:04.459512",
     "exception": false,
     "start_time": "2024-04-17T18:31:04.428878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "author_df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6f2de9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T18:31:04.473292Z",
     "iopub.status.busy": "2024-04-17T18:31:04.472627Z",
     "iopub.status.idle": "2024-04-17T18:31:05.709546Z",
     "shell.execute_reply": "2024-04-17T18:31:05.708480Z"
    },
    "papermill": {
     "duration": 1.246172,
     "end_time": "2024-04-17T18:31:05.711834",
     "exception": false,
     "start_time": "2024-04-17T18:31:04.465662",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# log10-transform downloads\n",
    "df['log10_downloads'] = df['downloads'].apply(lambda x: np.log10(1+x))\n",
    "df = df[~df['log10_downloads'].isnull()]\n",
    "    \n",
    "df['lastModified_year'] = pd.to_datetime(df['lastModified']).dt.year\n",
    "\n",
    "\n",
    "# Select only specific columns of interest\n",
    "selected_cols = ['log10_downloads', 'author', 'gated',\n",
    "       'authorData.type', 'authorData.isPro', 'authorData.isHf',\n",
    "       'pipeline_tag', 'lastModified_year']\n",
    "df = df[selected_cols]\n",
    "\n",
    "print(df.shape)  # Prints the dimensions (rows and columns) of the filtered DataFrame\n",
    "df.sample(10).T  # Displays a random sample of 5 rows transposed for better visibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2775a3c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T18:31:05.726125Z",
     "iopub.status.busy": "2024-04-17T18:31:05.725778Z",
     "iopub.status.idle": "2024-04-17T18:31:05.731732Z",
     "shell.execute_reply": "2024-04-17T18:31:05.730888Z"
    },
    "papermill": {
     "duration": 0.015359,
     "end_time": "2024-04-17T18:31:05.733751",
     "exception": false,
     "start_time": "2024-04-17T18:31:05.718392",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adc65ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T18:31:05.748871Z",
     "iopub.status.busy": "2024-04-17T18:31:05.748496Z",
     "iopub.status.idle": "2024-04-17T18:31:05.892140Z",
     "shell.execute_reply": "2024-04-17T18:31:05.890665Z"
    },
    "papermill": {
     "duration": 0.154134,
     "end_time": "2024-04-17T18:31:05.894647",
     "exception": false,
     "start_time": "2024-04-17T18:31:05.740513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036621e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T18:31:05.909660Z",
     "iopub.status.busy": "2024-04-17T18:31:05.909250Z",
     "iopub.status.idle": "2024-04-17T18:31:05.954968Z",
     "shell.execute_reply": "2024-04-17T18:31:05.953302Z"
    },
    "papermill": {
     "duration": 0.05622,
     "end_time": "2024-04-17T18:31:05.957462",
     "exception": false,
     "start_time": "2024-04-17T18:31:05.901242",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb9aebd",
   "metadata": {
    "papermill": {
     "duration": 0.006504,
     "end_time": "2024-04-17T18:31:05.970708",
     "exception": false,
     "start_time": "2024-04-17T18:31:05.964204",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48c3080",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T18:31:05.986095Z",
     "iopub.status.busy": "2024-04-17T18:31:05.985728Z",
     "iopub.status.idle": "2024-04-17T18:31:05.992749Z",
     "shell.execute_reply": "2024-04-17T18:31:05.991017Z"
    },
    "papermill": {
     "duration": 0.017702,
     "end_time": "2024-04-17T18:31:05.995376",
     "exception": false,
     "start_time": "2024-04-17T18:31:05.977674",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Accessing DataFrame columns\n",
    "# This line of code retrieves the column names from a DataFrame called 'df'.\n",
    "# It allows you to access and work with the names of the columns in the DataFrame.\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e7c888",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T18:31:06.011267Z",
     "iopub.status.busy": "2024-04-17T18:31:06.010927Z",
     "iopub.status.idle": "2024-04-17T18:31:06.042612Z",
     "shell.execute_reply": "2024-04-17T18:31:06.041346Z"
    },
    "papermill": {
     "duration": 0.042569,
     "end_time": "2024-04-17T18:31:06.045106",
     "exception": false,
     "start_time": "2024-04-17T18:31:06.002537",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.sample(5).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77d516e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T18:31:06.060760Z",
     "iopub.status.busy": "2024-04-17T18:31:06.060421Z",
     "iopub.status.idle": "2024-04-17T18:31:08.852395Z",
     "shell.execute_reply": "2024-04-17T18:31:08.851240Z"
    },
    "papermill": {
     "duration": 2.803258,
     "end_time": "2024-04-17T18:31:08.855511",
     "exception": false,
     "start_time": "2024-04-17T18:31:06.052253",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Select the main label.\n",
    "main_label = 'log10_downloads'\n",
    "\n",
    "# Set up a rare label encoder for selected columns.\n",
    "for col in df.columns:\n",
    "    if col != main_label:\n",
    "        df[col] = df[col].fillna('None').astype(str)\n",
    "        encoder = RareLabelEncoder(n_categories=1, max_n_categories=500, replace_with='Other', tol=20.0 / df.shape[0])\n",
    "        df[col] = encoder.fit_transform(df[[col]])\n",
    "\n",
    "print(df.shape)  # Print the shape of the resulting DataFrame.\n",
    "df.sample(10).T  # Display a sample of 10 rows, transposed for easier readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59da3747",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T18:31:08.871680Z",
     "iopub.status.busy": "2024-04-17T18:31:08.871328Z",
     "iopub.status.idle": "2024-04-17T18:31:09.024702Z",
     "shell.execute_reply": "2024-04-17T18:31:09.023629Z"
    },
    "papermill": {
     "duration": 0.164165,
     "end_time": "2024-04-17T18:31:09.026973",
     "exception": false,
     "start_time": "2024-04-17T18:31:08.862808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5218bca3",
   "metadata": {
    "papermill": {
     "duration": 0.007029,
     "end_time": "2024-04-17T18:31:09.041492",
     "exception": false,
     "start_time": "2024-04-17T18:31:09.034463",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0185953",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T18:31:09.057799Z",
     "iopub.status.busy": "2024-04-17T18:31:09.057408Z",
     "iopub.status.idle": "2024-04-17T18:31:11.118390Z",
     "shell.execute_reply": "2024-04-17T18:31:11.117576Z"
    },
    "papermill": {
     "duration": 2.071485,
     "end_time": "2024-04-17T18:31:11.120242",
     "exception": false,
     "start_time": "2024-04-17T18:31:09.048757",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Initialize data\n",
    "# Extract the values of the 'main_label' column and reshape it into a 1D array as 'y'\n",
    "y = df[main_label].values.reshape(-1,)\n",
    "# Create the feature matrix 'X' by dropping the 'main_label' column from the DataFrame 'df'\n",
    "X = df.drop([main_label], axis=1)\n",
    "\n",
    "# Identify categorical columns in the DataFrame 'df'\n",
    "# These columns contain non-numeric data\n",
    "cat_cols = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Create a list of indices for categorical columns in the feature matrix 'X'\n",
    "cat_cols_idx = [list(X.columns).index(c) for c in cat_cols]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# - 'X_train' and 'y_train' will contain the training features and labels, respectively\n",
    "# - 'X_test' and 'y_test' will contain the testing features and labels, respectively\n",
    "# The split is done with a 50% test size, a random seed of 0, and stratification based on the selected column\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0, stratify=df[['author']])\n",
    "\n",
    "# Print the dimensions of the training and testing sets\n",
    "# This provides insight into the sizes of the datasets\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1e6dcd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T18:31:11.137259Z",
     "iopub.status.busy": "2024-04-17T18:31:11.136903Z",
     "iopub.status.idle": "2024-04-17T18:33:26.811475Z",
     "shell.execute_reply": "2024-04-17T18:33:26.810124Z"
    },
    "papermill": {
     "duration": 135.692347,
     "end_time": "2024-04-17T18:33:26.820007",
     "exception": false,
     "start_time": "2024-04-17T18:31:11.127660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Initialize the training and testing data pools using CatBoost's Pool class\n",
    "train_pool = Pool(X_train, \n",
    "                  y_train, \n",
    "                  cat_features=cat_cols_idx)  # Create a training data pool with categorical features\n",
    "test_pool = Pool(X_test,\n",
    "                 y_test,\n",
    "                 cat_features=cat_cols_idx)  # Create a testing data pool with categorical features\n",
    "\n",
    "# Specify the training parameters for the CatBoostRegressor model\n",
    "model = CatBoostRegressor(iterations=1500,    # Number of boosting iterations\n",
    "                          depth=5,           # Maximum depth of trees in the ensemble\n",
    "                          verbose=0,         # Set verbosity level to 0 (no output during training)\n",
    "                          learning_rate=0.08,  # Learning rate for gradient boosting\n",
    "                          early_stopping_rounds=100, # Early stopping rounds\n",
    "                          loss_function='RMSE')  # Loss function to optimize (Root Mean Squared Error)\n",
    "\n",
    "# Train the CatBoostRegressor model on the training data\n",
    "model.fit(train_pool, eval_set=test_pool)\n",
    "\n",
    "# Make predictions using the trained model on both the training and testing data\n",
    "y_train_pred = model.predict(train_pool)  # Predictions on the training data\n",
    "y_test_pred = model.predict(test_pool)    # Predictions on the testing data\n",
    "\n",
    "# Calculate and print the Root Mean Squared Error (RMSE) scores for training and testing data\n",
    "rmse_train = mean_squared_error(y_train, y_train_pred, squared=False)  # RMSE for training data\n",
    "rmse_test = mean_squared_error(y_test, y_test_pred, squared=False)     # RMSE for testing data\n",
    "\n",
    "# Print the rounded RMSE scores\n",
    "print(f\"RMSE score for train {round(rmse_train, 4)} dex, and for test {round(rmse_test, 4)} dex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679d26a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T18:33:26.836141Z",
     "iopub.status.busy": "2024-04-17T18:33:26.835741Z",
     "iopub.status.idle": "2024-04-17T18:33:26.880110Z",
     "shell.execute_reply": "2024-04-17T18:33:26.878253Z"
    },
    "papermill": {
     "duration": 0.055477,
     "end_time": "2024-04-17T18:33:26.882695",
     "exception": false,
     "start_time": "2024-04-17T18:33:26.827218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate the baseline RMSE (Root Mean Squared Error) scores for the training and test datasets.\n",
    "\n",
    "# For the training dataset:\n",
    "\n",
    "# Calculate the RMSE by comparing the actual target values (y_train) with the predicted values,\n",
    "# where the predicted values are the mean of the training target values repeated for each data sample.\n",
    "rmse_bs_train = mean_squared_error(y_train, [np.mean(y_train)]*len(y_train), squared=False)\n",
    "\n",
    "# For the test dataset:\n",
    "\n",
    "# Calculate the RMSE by comparing the actual target values (y_test) with the predicted values,\n",
    "# where the predicted values are the mean of the training target values repeated for each test data sample.\n",
    "rmse_bs_test = mean_squared_error(y_test, [np.mean(y_train)]*len(y_test), squared=False)\n",
    "\n",
    "# Print the rounded baseline RMSE scores for both the training and test datasets.\n",
    "print(f\"RMSE baseline score for train {round(rmse_bs_train, 4)} dex, and for test {round(rmse_bs_test, 4)} dex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e90367d",
   "metadata": {
    "papermill": {
     "duration": 0.00746,
     "end_time": "2024-04-17T18:33:26.898038",
     "exception": false,
     "start_time": "2024-04-17T18:33:26.890578",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Explanations with SHAP values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebff4b9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T18:33:26.914937Z",
     "iopub.status.busy": "2024-04-17T18:33:26.914515Z",
     "iopub.status.idle": "2024-04-17T18:33:26.921483Z",
     "shell.execute_reply": "2024-04-17T18:33:26.920298Z"
    },
    "papermill": {
     "duration": 0.01818,
     "end_time": "2024-04-17T18:33:26.923901",
     "exception": false,
     "start_time": "2024-04-17T18:33:26.905721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25f0c79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T18:33:26.940704Z",
     "iopub.status.busy": "2024-04-17T18:33:26.940327Z",
     "iopub.status.idle": "2024-04-17T18:33:58.226816Z",
     "shell.execute_reply": "2024-04-17T18:33:58.225595Z"
    },
    "papermill": {
     "duration": 31.307799,
     "end_time": "2024-04-17T18:33:58.239404",
     "exception": false,
     "start_time": "2024-04-17T18:33:26.931605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Initialize the SHAP library for visualization\n",
    "shap.initjs()\n",
    "\n",
    "# Create a TreeExplainer object for the 'model' (assumes 'model' is a tree-based model like a Random Forest or XGBoost)\n",
    "ex = shap.TreeExplainer(model)\n",
    "\n",
    "# Calculate SHAP values for the 'X_test' data using the TreeExplainer\n",
    "shap_values = ex.shap_values(X_test)\n",
    "\n",
    "# Generate a summary plot to visualize the impact of features on model predictions\n",
    "shap.summary_plot(shap_values, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e58fe0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T18:33:58.263483Z",
     "iopub.status.busy": "2024-04-17T18:33:58.263066Z",
     "iopub.status.idle": "2024-04-17T18:33:58.269004Z",
     "shell.execute_reply": "2024-04-17T18:33:58.268310Z"
    },
    "papermill": {
     "duration": 0.020517,
     "end_time": "2024-04-17T18:33:58.271316",
     "exception": false,
     "start_time": "2024-04-17T18:33:58.250799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate the expected values using a variable named 'ex.expected_value'.\n",
    "expected_values = ex.expected_value\n",
    "\n",
    "# Print the average predicted label\n",
    "print(f\"Average predicted downloads is {round(10**expected_values):,}\")\n",
    "\n",
    "# Print the average actual label from 'y_test'\n",
    "print(f\"Average actual downloads is {round(10**np.mean(y_test)):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fdc76e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T18:33:58.295347Z",
     "iopub.status.busy": "2024-04-17T18:33:58.294913Z",
     "iopub.status.idle": "2024-04-17T18:34:04.535617Z",
     "shell.execute_reply": "2024-04-17T18:34:04.534575Z"
    },
    "papermill": {
     "duration": 6.255493,
     "end_time": "2024-04-17T18:34:04.538394",
     "exception": false,
     "start_time": "2024-04-17T18:33:58.282901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a function named 'show_shap' that visualizes SHAP values for a specific feature.\n",
    "# Parameters:\n",
    "#   - col: The name of the feature for which SHAP values will be visualized.\n",
    "#   - shap_values: SHAP values calculated for the model's predictions.\n",
    "#   - label: The label to be displayed in the plot title.\n",
    "#   - X_test: The DataFrame containing the test data.\n",
    "#   - ylabel: The label for the y-axis in the plot (default is 'points').\n",
    "def show_shap(col, shap_values=shap_values, label=main_label, X_test=X_test, ylabel='dex'):\n",
    "    # Create a copy of the test data DataFrame.\n",
    "    df_infl = X_test.copy()\n",
    "    \n",
    "    # Add a new column 'shap_' to the DataFrame containing SHAP values for the specified feature.\n",
    "    df_infl['shap_'] = shap_values[:, df_infl.columns.tolist().index(col)]\n",
    "    \n",
    "    # Calculate the mean SHAP values and standard deviation grouped by the specified feature.\n",
    "    gain = round(df_infl.groupby(col)['shap_'].mean(), 4)\n",
    "    gain_std = round(df_infl.groupby(col)['shap_'].std(), 4)\n",
    "    \n",
    "    # Count the number of data points for each category of the specified feature.\n",
    "    cnt = df_infl.groupby(col)['shap_'].count()\n",
    "    \n",
    "    # Create a dictionary containing the feature, mean SHAP values, standard deviation, and count.\n",
    "    dd_dict = {'col': list(gain.index), 'gain': list(gain.values), 'gain_std': list(gain_std.values), 'count': cnt}\n",
    "        \n",
    "    # Create a DataFrame from the dictionary and sort it by 'gain' in descending order.\n",
    "    df_res = pd.DataFrame.from_dict(dd_dict).sort_values('gain', ascending=False).set_index('col')\n",
    "    \n",
    "    # Replace \"$\" by \"*\" to use in matplotlib\n",
    "    if any([('$' in str(idx)) for idx in set(df_res.index)]):\n",
    "        print('Replacing \"$\" by \"*\" to use in matplotlib')\n",
    "        df_res.index = [c.replace('$','*') for c in df_res.index]\n",
    "    \n",
    "    \n",
    "    # Create a plot to visualize the SHAP values with error bars.\n",
    "    plt.figure(figsize=(30, 20))\n",
    "    plt.errorbar(df_res.index, df_res['gain'].values, yerr=df_res['gain_std'].values, fmt=\"o\", color=\"r\")\n",
    "    \n",
    "    # Set plot title and axis labels.\n",
    "    plt.title(f'SHAP values for column {col}, label {label}')\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.tick_params(axis=\"x\", rotation=90)\n",
    "    \n",
    "    # Display the plot and the DataFrame with results.\n",
    "    plt.show()\n",
    "    print(df_res)\n",
    "    \n",
    "    # Return the function.\n",
    "    return\n",
    "\n",
    "# Loop through the columns in the test data.\n",
    "for col in X_test.columns:\n",
    "    print()  # Print an empty line for better readability.\n",
    "    print(col)  # Print the name of the current column.\n",
    "    print()  # Print another empty line for separation.\n",
    "\n",
    "    # Call the 'show_shap' function to visualize SHAP values for the current column.\n",
    "    show_shap(col, shap_values, label=main_label, X_test=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dab5de9",
   "metadata": {
    "papermill": {
     "duration": 0.020829,
     "end_time": "2024-04-17T18:34:04.580940",
     "exception": false,
     "start_time": "2024-04-17T18:34:04.560111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8057239,
     "datasetId": 3938888,
     "sourceId": 7948150,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30587,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 223.873161,
   "end_time": "2024-04-17T18:34:06.026585",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-17T18:30:22.153424",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
